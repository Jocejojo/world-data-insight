# ğŸŒ EPI Coding Challenge â€” World Data Insight

This project explores and analyses global country data from `worldData.csv`.  
It performs full data cleaning, answers key analytical questions, and provides an interactive CLI for users to filter, summarise, and explore the dataset.  
It also generates a set of visualisations that highlight relationships between GDP, population, and life expectancy across regions and subregions.

---

## ğŸ§© Project Structure
```
world-data-insight/
â”œâ”€ data/
â”‚  â””â”€ worldData.csv
â”œâ”€ src/
â”‚  â”œâ”€ main.py          # CLI entry point â€“ runs cleaning, analysis, visualisations, and filtering
â”‚  â”œâ”€ io_utils.py       # Data loading and encoding/delimiter detection
â”‚  â”œâ”€ cleaning.py       # Data cleaning pipeline
â”‚  â”œâ”€ analysis.py       # Functions for analytical questions and summary writing
â”‚  â””â”€ visualisation.py  # Visualisation functions 
â”œâ”€ outputs/
â”œâ”€ requirements.txt
â””â”€ README.md
```

---

## âš™ï¸ Environment Setup

Python: 3.10 or above recommended

Itâ€™s recommended to run this project inside a virtual environment (venv):

```bash
python -m venv .venv
.\.venv\Scripts\activate   # on Windows
source .venv/bin/activate  # on macOS/Linux
```

Install dependencies:
```bash
pip install -r requirements.txt
```

Dependencies include pandas, numpy, matplotlib, tabulate, and seaborn.
The project was tested in a clean virtual environment (venv) on Windows.

---

## ğŸš€ Running the Project

From the project root:
```bash
python src/main.py
```

The program will:
1. Read the raw dataset (`data/worldData.csv`)
2. Clean and validate the data  
   â†’ `outputs/worldData_clean.csv`
3. Generate a cleaning report  
   â†’ `outputs/cleaning_report.txt`
4. Run analytical queries and save the answers  
   â†’ `outputs/summary.txt`
5. Create several visualisation charts (see below)
6. Launch an **interactive command-line interface (CLI)** for live filtering and statistics

---

# ğŸ§® Interactive CLI

After cleaning and analysis, the program enters an interactive mode.
You can filter data by `continent`, `region_un`, `subregion`, and `type`.
Simply press **Enter** to skip any field.

Enter continent (or press Enter for all):
Enter region_un (or press Enter for all):
Enter subregion (or press Enter for all):
Enter type (or press Enter for all):


The CLI then prints:
- How many rows match your filters  
- A list of countries included in that subset  
- Summary statistics (`count, sum, mean, median, min, max, std`)  
  for `area_km2`, `pop`, `lifeExp`, and `gdpPercap`

You can also save the filtered subset by running:

```bash
python src/main.py --save-subset
```

This saves your results under outputs/ with a descriptive timestamped filename, for example:

`filtered_Africa_all_Eastern_Africa_all_20251027-174530.csv`


Automatic outputs (clean data, reports, charts) are overwritten each run,
while user-saved subsets always include a timestamp to preserve history.

---

## ğŸ“Š Visualisations

All charts are automatically generated under `outputs/` during runtime.

| Chart | File | Description |
|--------|------|-------------|
| **Average GDP per Capita by Continent** | `avg_gdp_by_continent.png` | A bar chart comparing the mean GDP per capita across continents. |
| **GDP vs Life Expectancy by Subregion** | `gdp_vs_lifeExp_by_subregion.png` | A scatter plot showing average life expectancy vs GDP per capita, grouped by subregion. |
| **Population Density by Region** | `population_density_by_region.png` | A bar chart displaying average population density (people per kmÂ²) for each UN region. |

All charts use consistent styling (Seaborn whitegrid theme) and are saved at 300 dpi for clarity in reports.

---

## ğŸ§¹ Data Cleaning Pipeline

All data-cleaning logic lives in cleaning.py inside the clean_world_data() function.
The process is explicit, reproducible, and documented step by step:

1. **Column normalisation** â€“ trims BOMs, renames headers, drops unnamed columns  
2. **Type conversion** â€“ converts numeric fields to `float`/`int` safely  
3. **Missing identifiers** â€“ removes rows missing `iso_a2` or `name_long`  
4. **Invalid values** â€“ filters out `pop <= 0`, `area_km2 <= 0`, `gdpPercap <= 0`, and unrealistic `lifeExp` values  
5. **Imputation** â€“ fills missing `lifeExp` and `gdpPercap` via median (subregion â†’ continent â†’ global)  
6. **De-duplication** â€“ keeps rows with the most valid metrics per `iso_a2`  
7. **Derived field** â€“ adds `pop_density = pop / area_km2`  
8. **Report** â€“ writes a readable summary of dropped, filled, and deduplicated rows to `outputs/cleaning_report.txt`

---

## ğŸ“ˆ Analytical Results

Analytical functions in analysis.py answer the four required questions and write results to `outputs/summary.txt`:

Continent with the largest number of countries: Africa (45)
Region with largest combined area in sq. km: Americas (42,230,537.74 kmÂ²)
Country with highest life expectancy: Japan (83.59 years)
Subregion with lowest average GDP per capita: Eastern Africa (1,755.01)
Subregion with highest average GDP per capita: Western Europe (56,884.58)

---

## ğŸ” Reproducibility

Every automatic output (cleaned data, analysis summary, and charts) is written to a fixed path and overwrites previous runs for deterministic results.
Only CLI-exported subsets use timestamped filenames to preserve exploration history.

---

## ğŸ“š Notes & Limitations

- The project focuses on CLI functionality; a lightweight GUI (Streamlit) could easily reuse the same logic later.  
- Charts rely on Matplotlib and Seaborn; ensure both are installed.  
- Some countries in the raw data may still have rounding or boundary inconsistencies (as expected from world aggregates).  
- All outputs are reproducible â€” each run regenerates the full pipeline from raw CSV.

---

## ğŸ‘©â€ğŸ’» Author

**Jocelyn Qian**  
ğŸ“ Wellington, New Zealand  
ğŸ“§ [qjxapril@gmail.com](mailto:qjxapril@gmail.com)  
ğŸ”— [linkedin.com/in/jocelyn-qian](https://linkedin.com/in/jocelyn-qian)  
ğŸ’» [github.com/Jocejojo](https://github.com/Jocejojo)